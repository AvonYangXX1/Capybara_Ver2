---
title: "skeleton of 715 project"
output: html_document
date: "2023-12-09"
---
Author: Avon Yang, Nuoya Jiang
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

All text in human-readable format except comments should go into the report in the end.

#TO DO
Rubric 1: 
Statement of the research question:

1 dependent variable:

8 independent variable:
ã€€ 
Goal:

Rubric 1.5:

Literature research and motivation:

Rubric 2: EDA and QC of data
```{r}
subset_df <- read.csv("nhanes_13_14_subset.csv")

#age, gender, income, potassium, cholesterol, protein, serum glucose, blood sodium, bmi
data <- subset_df[, c("RIDAGEYR", "RIAGENDR", "INDFMIN2","LBXSKSI", "LBXSCH", "LBXSTP", "LBXSGL", "LBXSNASI","BMXBMI")]
# TO DO: inspect if we have NA values
any_na <- any(is.na(data))
print(paste("Are there any NA values in the data frame? ", any_na))
# TO DO: inspect num/cat, if num, what scale?
str(data)
# Summary statistics for numeric columns
summary(data)

# TO DO: drop NA
data <- na.omit(data)

library(tidyr)
data <- na.omit(data)
str(data)
summary(data)
```


```{r}
# TO DO: EDA plots
library(ggplot2)
#install.packages("gridExtra")
library(gridExtra)

plots_list <- list()

numeric_vars <- names(data)[sapply(data, is.numeric) & names(data) != "BMXBMI"]
for (var in numeric_vars) {
    p <- ggplot(data, aes_string(x = var, y = "BMXBMI")) + 
        geom_point() +
        labs(x = var, y = "BMI") +
        theme_minimal()
    plots_list[[var]] <- p
}

do.call(grid.arrange, c(plots_list, ncol = 2))

```

```{r}
library(dplyr)
data_overweight <- data %>% 
  filter(BMXBMI >= 24.9) %>% 
  mutate(BMI_Category = "BMI >= 24.9")
data_normal <- data %>% 
  filter(BMXBMI < 24.9) %>% 
  mutate(BMI_Category = "BMI < 24.9")
combined_data <- rbind(data_overweight, data_normal)
create_combined_histograms <- function(dataset) {
  plots_list <- list()
  numeric_vars <- names(dataset)[sapply(dataset, is.numeric) & names(dataset) != "BMXBMI"]
  for (var in numeric_vars) {
    p <- ggplot(dataset, aes_string(x = var, fill = "BMI_Category")) + 
      geom_histogram(position = "identity", alpha = 0.5, bins = 30) +
      scale_fill_manual(values = c("skyblue", "pink")) +
      labs(x = var, y = "Frequency", title = paste("Histogram of", var)) +
      theme_minimal()+
      theme(plot.title = element_text(size = 10)) 
    plots_list[[var]] <- p
  }
  return(plots_list)
}
combined_histograms <- create_combined_histograms(combined_data)
do.call(grid.arrange, c(combined_histograms, ncol = 2))
```

```{r}
# TO DO: correlation and collinearity
correlation_matrix <- cor(data[, -ncol(data)])
library(corrplot)
corrplot(correlation_matrix, method = "color", addCoef.col = "black", type = "upper", order = "hclust", tl.col="black", tl.srt=45)
```


```{r}
# TO DO: scaling
data_numeric <- as.data.frame(lapply(data, as.numeric))
data_scaled <- as.data.frame(scale(data_numeric))
```

Rubric 3: 
Conduct a two- or multi-sample hypothesis test
Identify two variables that you want to test for associations, where
at least one is categorical. Choose variables relevant to your
research question
Choose the appropriate test (t test, ANOVA, Wilcox rank-sum,
Wilcoxon signed-rank, Kruskal-Wallis, binomial test, proportion test,
chi-square test, Fisher exact test)
Check any assumptions required and justify your choice of test
Null hypothesis
```{r}
male_data <- data[data$RIAGENDR == 1, "BMXBMI"]
female_data <- data[data$RIAGENDR == 2, "BMXBMI"]
variance_test_result <- var.test(male_data, female_data)
print(variance_test_result$p.value)
t_test_result <- t.test(male_data, female_data)
print(t_test_result)
```

Rubric 4-5:
Choose a regression or classification model and run the model
justify decision
variable selection
assumption check
report key statistics
```{r}
data$y <- ifelse(data$BMXBMI <= 24.9, 0, 1)
set.seed(715)

cor_matrix<- cor(data)
print(cor_matrix)

split_index <- sample(1:nrow(data), 0.8 * nrow(data))
X_train <- data[split_index, c("RIDAGEYR", "RIAGENDR", "LBXSCH", "LBXSTP", "LBXSGL", "LBXSNASI")]
y_train <- data[split_index, "y"]

X_test <- data[-split_index, c("RIDAGEYR", "RIAGENDR","LBXSCH", "LBXSTP", "LBXSGL", "LBXSNASI")]
y_test <- data[-split_index, "y"]
```


```{r}
library(tree)
tree_model <- tree(y_train ~ ., data = X_train)


```

Rubric 6: 
Evaluate model fit
Choose, calculate, and appropriately interpret a metric
Justify the metric you chose based on the goal of your model
Include 1+ plot that you use to evaluate model fit
```{r}
library(caret)
library(pROC)
predictions <- predict(tree_model, newdata = X_train)

binary_predictions <- as.numeric(ifelse(predictions >= 0.5, 1, 0))
confusion_matrix <- confusionMatrix(factor(binary_predictions), factor(y_train))
print(confusion_matrix)
print(confusion_matrix)
accuracy <- confusion_matrix$overall["Accuracy"]
print(paste("Accuracy:", accuracy))

roc_curve <- roc(y_train, as.numeric(predictions))
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
plot(roc_curve, main = "ROC Curve", col = "lightblue", lwd = 2)
```

Rubric 7:
Compare your model to one with different variables
can change the variables in any way that you think would be
interesting: e.g., add/remove variables, different regularization or
scaling. Justify the alternative model that you choose.
```{r}
X_train_d <- data[split_index, c("RIDAGEYR", "RIAGENDR", "INDFMIN2")]

X_test_d <- data[-split_index, c("RIDAGEYR", "RIAGENDR", "INDFMIN2")]

tree_model_d <- tree(y_train ~ ., data = X_train_d)
predictions_d <- predict(tree_model_d, newdata = X_train_d)

binary_predictions_d <- as.numeric(ifelse(predictions_d >= 0.5, 1, 0))
confusion_matrix_d <- confusionMatrix(factor(binary_predictions_d), factor(y_train))
accuracy_d <- confusion_matrix_d$overall["Accuracy"]
print(paste("Demographic Accuracy:", accuracy_d))

X_train_l <- data[split_index, c("LBXSKSI", "LBXSCH", "LBXSTP", "LBXSGL", "LBXSNASI")]

X_test_l <- data[-split_index, c("LBXSKSI", "LBXSCH", "LBXSTP", "LBXSGL", "LBXSNASI")]

tree_model_l <- tree(y_train ~ ., data = X_train_l)
predictions_l <- predict(tree_model_l, newdata = X_train_l)

binary_predictions_l <- as.numeric(ifelse(predictions_l >= 0.5, 1, 0))
confusion_matrix_l <- confusionMatrix(factor(binary_predictions_l), factor(y_train))
accuracy_l <- confusion_matrix_l$overall["Accuracy"]
print(paste("Blood Lab Test Accuracy:", accuracy_l))
```

Rubric 8:
Conduct one follow-up analysis
```{r}
predictions <- predict(tree_model, newdata = X_test)

binary_predictions <- as.numeric(ifelse(predictions >= 0.5, 1, 0))
confusion_matrix <- confusionMatrix(factor(binary_predictions), factor(y_test))
print(confusion_matrix)
print(confusion_matrix)
accuracy <- confusion_matrix$overall["Accuracy"]
print(paste("Accuracy:", accuracy))

roc_curve <- roc(y_test, as.numeric(predictions))
auc_value <- auc(roc_curve)
print(paste("AUC:", auc_value))
plot(roc_curve, main = "ROC Curve", col = "lightblue", lwd = 2)
```


```{r}
X_train <- data[split_index, c("RIDAGEYR", "RIAGENDR", "INDFMIN2","LBXSKSI", "LBXSCH", "LBXSTP", "LBXSGL", "LBXSNASI")]

X_test <- data[-split_index, c("RIDAGEYR", "RIAGENDR", "INDFMIN2","LBXSKSI", "LBXSCH", "LBXSTP", "LBXSGL", "LBXSNASI")]
tree_model_gini <- tree(y_train ~ ., data = X_train, split = "gini")
predictions_g <- predict(tree_model_gini, newdata = X_train)

binary_predictions_g <- as.numeric(ifelse(predictions_g >= 0.5, 1, 0))
confusion_matrix_g <- confusionMatrix(factor(binary_predictions_g), factor(y_train))
accuracy_g <- confusion_matrix_g$overall["Accuracy"]
print(paste("Train Accuracy:", accuracy_g))

predictions_g <- predict(tree_model_gini, newdata = X_test)
binary_predictions_g <- as.numeric(ifelse(predictions_g >= 0.5, 1, 0))
confusion_matrix_g <- confusionMatrix(factor(binary_predictions_g), factor(y_test))
accuracy_g <- confusion_matrix_g$overall["Accuracy"]
print(paste("Test Accuracy:", accuracy_g))

```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
